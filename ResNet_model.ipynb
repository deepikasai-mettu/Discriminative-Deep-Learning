{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19c7e6",
   "metadata": {
    "id": "bb19c7e6"
   },
   "outputs": [],
   "source": [
    "pip install kagglehub[pandas-datasets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62d5ad6",
   "metadata": {
    "id": "a62d5ad6",
    "outputId": "2ed7d8c1-485a-4f3c-976d-75b4083025ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\deepi\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import kagglehub\n",
    "import os\n",
    "from tensorflow.data import AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557877e1",
   "metadata": {
    "id": "557877e1",
    "outputId": "d0f58bf7-9705-446a-bdde-27c1dafa42bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/jessicali9530/celeba-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1.33G/1.33G [01:56<00:00, 12.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dir = kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")  # Download dataset\n",
    "image_dir = os.path.join(train_dir, \"img_align_celeba\")  # Path to images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333c621",
   "metadata": {
    "id": "c333c621"
   },
   "source": [
    "### Ignore Until here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53375fe0",
   "metadata": {
    "id": "53375fe0"
   },
   "outputs": [],
   "source": [
    "pip install --user kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5539515",
   "metadata": {
    "id": "c5539515"
   },
   "outputs": [],
   "source": [
    "pip install --user pyxlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a6aba46",
   "metadata": {
    "id": "8a6aba46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 19:52:32.742736: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759189952.936079  516823 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759189952.984839  516823 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759189953.507345  516823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759189953.507395  516823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759189953.507399  516823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759189953.507402  516823 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.data import AUTOTUNE\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25fd7e94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "25fd7e94",
    "outputId": "5e63b6df-0a98-4151-abbd-5016189f48d4"
   },
   "outputs": [],
   "source": [
    "attributes_df = pd.read_csv(\"identity_CelebA.txt\", delim_whitespace=True, names=['image_id','Celeb_identity'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "265c7b39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "265c7b39",
    "outputId": "391d6113-c8d9-4e52-af39-2c0ad7a49f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 202599\n",
      "After removing missing values: 202599\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original dataset size: {len(attributes_df)}\")\n",
    "attributes_df = attributes_df.dropna(subset=['image_id', 'Celeb_identity'])\n",
    "print(f\"After removing missing values: {len(attributes_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d103578",
   "metadata": {
    "id": "0d103578"
   },
   "outputs": [],
   "source": [
    "attributes_df['Celeb_identity'] = attributes_df['Celeb_identity'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeaff3da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeaff3da",
    "outputId": "4ea30cae-31fd-493b-f047-e53a130ce06a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (202599, 2)\n",
      "Columns: ['image_id', 'Celeb_identity']\n",
      "Number of unique identities: 10177\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset Shape: {attributes_df.shape}\")\n",
    "print(f\"Columns: {list(attributes_df.columns)}\")\n",
    "print(f\"Number of unique identities: {attributes_df['Celeb_identity'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61631468",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61631468",
    "outputId": "8b8255a5-245b-4aaf-8022-352c237f8e88"
   },
   "outputs": [],
   "source": [
    "train_dir = kagglehub.dataset_download(\"jessicali9530/celeba-dataset\")  # Download dataset\n",
    "image_dir = os.path.join(train_dir, \"img_align_celeba\", \"img_align_celeba\")  # Path to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5104d31d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5104d31d",
    "outputId": "cda9a89a-9914-42c7-cc35-3011e7b5bce4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 202599\n",
      "Number of classes (identities): 10177\n",
      "Original identity range: 1 to 10177\n",
      "Encoded label range: 0 to 10176\n"
     ]
    }
   ],
   "source": [
    "# Prepare image paths and labels\n",
    "image_paths = [os.path.join(image_dir, img_name) for img_name in attributes_df['image_id']]\n",
    "\n",
    "# Encode identity labels to integers (0 to num_classes-1)\n",
    "label_encoder = LabelEncoder()\n",
    "identity_labels = label_encoder.fit_transform(attributes_df['Celeb_identity'])\n",
    "num_classes = len(label_encoder.classes_)\n",
    "\n",
    "print(f\"Total images: {len(image_paths)}\")\n",
    "print(f\"Number of classes (identities): {num_classes}\")\n",
    "print(f\"Original identity range: {attributes_df['Celeb_identity'].min()} to {attributes_df['Celeb_identity'].max()}\")\n",
    "print(f\"Encoded label range: {identity_labels.min()} to {identity_labels.max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f7c0502",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f7c0502",
    "outputId": "5eba67d6-e06d-44ee-9eda-9aa5f6130288"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 19:52:50.255127: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batches: 5065\n",
      "Validation batches: 1267\n",
      "Image batch shape: (32, 128, 128, 3)\n",
      "Label batch shape: (32,)\n",
      "Label range: 39 to 10031\n"
     ]
    }
   ],
   "source": [
    "# to load and preprocess images\n",
    "def load_and_preprocess_image(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Create dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, identity_labels))\n",
    "\n",
    "# Apply preprocessing\n",
    "dataset = dataset.map(\n",
    "    load_and_preprocess_image,\n",
    "    num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "\n",
    "# Split into train/validation (80/20 split)\n",
    "total_size = len(image_paths)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "\n",
    "# Shuffle and split\n",
    "dataset = dataset.shuffle(buffer_size=10000, seed=42)\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Batch and prefetch for training\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "\n",
    "print(f\"Training batches: {len(train_dataset)}\")\n",
    "print(f\"Validation batches: {len(val_dataset)}\")\n",
    "\n",
    "# Optional: Cache datasets to speed up training (if you have enough memory/storage)\n",
    "# train_dataset = train_dataset.cache()\n",
    "# val_dataset = val_dataset.cache()\n",
    "\n",
    "# Verify the dataset\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Label batch shape: {labels.shape}\")\n",
    "    print(f\"Label range: {tf.reduce_min(labels)} to {tf.reduce_max(labels)}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "303cf605",
   "metadata": {
    "id": "303cf605"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_baseline_cnn(num_classes, input_shape=(128, 128, 3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255c547d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 900
    },
    "id": "255c547d",
    "outputId": "dd7f9333-e245-4f45-d164-8149737496c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating baseline CNN model...\n",
      "Model Architecture:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10177</span>)          │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,615,489</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10177\u001b[0m)          │     \u001b[38;5;34m2,615,489\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,268,737</span> (12.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,268,737\u001b[0m (12.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,267,777</span> (12.47 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,267,777\u001b[0m (12.47 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the model\n",
    "print(\"Creating baseline CNN model...\")\n",
    "baseline_model = create_baseline_cnn(num_classes)\n",
    "print(\"Model Architecture:\")\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c974604c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c974604c",
    "outputId": "4f225b93-89b1-4156-f8a5-f7716a2ac4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model compiled successfully!\n",
      "Total parameters: 3,268,737\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "baseline_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(f\"Model compiled successfully!\")\n",
    "print(f\"Total parameters: {baseline_model.count_params():,}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e185f24",
   "metadata": {
    "id": "9e185f24"
   },
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "EPOCHS = 20\n",
    "EARLY_STOPPING_PATIENCE = 5\n",
    "\n",
    "# Callbacks for better training\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=EARLY_STOPPING_PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ### tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        #monitor='val_loss',\n",
    "        #factor=0.5,\n",
    "       # patience=3,\n",
    "      #  min_lr=1e-7,\n",
    "     #   verbose=1\n",
    "    #),\n",
    "    #tf.keras.callbacks.ModelCheckpoint(\n",
    "        #filepath='baseline_cnn_best.h5',\n",
    "       # monitor='val_accuracy',\n",
    "      #  save_best_only=True,\n",
    "     #   verbose=1\n",
    "    #)\n",
    "]\n",
    "# Start training\n",
    "# history = baseline_model.fit(\n",
    "#     train_dataset,\n",
    "#     epochs=EPOCHS,\n",
    "#     validation_data=val_dataset,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# print(f\"\\nTraining completed!\")\n",
    "# print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "# print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36569a65",
   "metadata": {
    "id": "36569a65"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    image_dir,\n",
    "    labels=None,\n",
    "    label_mode=None,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Normalize the images to [0, 1] range\n",
    "def normalize(image):\n",
    "    return tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "# Apply the normalization\n",
    "train_dataset = train_dataset.map(normalize, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Prefetch to optimize dataset loading\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lX6iDTHmyu29",
   "metadata": {
    "id": "lX6iDTHmyu29"
   },
   "outputs": [],
   "source": [
    "# Count frequency of each identity\n",
    "top_ids = attributes_df['Celeb_identity'].value_counts().nlargest(1000).index.tolist()\n",
    "\n",
    "# Filter dataframe to only those identities\n",
    "filtered_df = attributes_df[attributes_df['Celeb_identity'].isin(top_ids)].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "MaogMhWDyu0G",
   "metadata": {
    "id": "MaogMhWDyu0G"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "filtered_df['encoded_label'] = label_encoder.fit_transform(filtered_df['Celeb_identity'])\n",
    "\n",
    "# Update image paths\n",
    "image_paths = [os.path.join(image_dir, img_name) for img_name in filtered_df['image_id']]\n",
    "identity_labels = filtered_df['encoded_label'].values\n",
    "NUM_CLASSES = len(label_encoder.classes_)  # should be 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dIWR_eWQyuxP",
   "metadata": {
    "id": "dIWR_eWQyuxP"
   },
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_paths, identity_labels))\n",
    "\n",
    "# Preprocessing\n",
    "dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "# Shuffle & Split (80/20)\n",
    "total_size = len(image_paths)\n",
    "train_size = int(0.8 * total_size)\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size=10000, seed=42)\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "# Batch and prefetch\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stV922-9rPH2",
   "metadata": {
    "id": "stV922-9rPH2"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "import time\n",
    "\n",
    "# ----------- Residual Block ------------\n",
    "def residual_block(x, filters, stride=1):\n",
    "    shortcut = x\n",
    "\n",
    "    # First conv\n",
    "    x = layers.Conv2D(filters, (3, 3), strides=stride, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Second conv\n",
    "    x = layers.Conv2D(filters, (3, 3), strides=1, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Adjust shortcut if dimensions change\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), strides=stride, padding='same')(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    x = layers.Add()([x, shortcut])\n",
    "    x = layers.ReLU()(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "hFcWDvierPFc",
   "metadata": {
    "id": "hFcWDvierPFc"
   },
   "outputs": [],
   "source": [
    "def build_resnet_style_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Initial conv\n",
    "    x = layers.Conv2D(64, (7, 7), strides=2, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = residual_block(x, 64)\n",
    "    x = residual_block(x, 128, stride=2)\n",
    "    x = residual_block(x, 256, stride=2)\n",
    "    x = residual_block(x, 512, stride=2)\n",
    "\n",
    "    # Classification head\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs, name=\"ResNet_Style\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WjrTesYVrPDI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjrTesYVrPDI",
    "outputId": "7e98af71-7b85-48b9-dc73-e6b1297a0e5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m 99/751\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:12\u001b[0m 755ms/step - accuracy: 0.0028 - loss: 7.0064"
     ]
    }
   ],
   "source": [
    "# Example config\n",
    "INPUT_SHAPE = (128, 128, 3)\n",
    "NUM_CLASSES = 1000  # <-- update for your dataset\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "\n",
    "# Assume X_train, y_train_cat, X_val, y_val_cat are ready\n",
    "resnet_model = build_resnet_style_model(INPUT_SHAPE, NUM_CLASSES)\n",
    "resnet_model.compile(\n",
    "    optimizer=optimizers.Adam(0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Training\n",
    "history_resnet = resnet_model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hiJnemjRv0_D",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hiJnemjRv0_D",
    "outputId": "f14b5c6a-dac4-489d-d9f8-295f9b6505d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 128, 128, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SpWMHU7ErPAo",
   "metadata": {
    "id": "SpWMHU7ErPAo"
   },
   "outputs": [],
   "source": [
    "_# Evaluation\n",
    "resnet_test_loss, resnet_test_acc, resnet_test_top5 = resnet_model.evaluate(X_test, y_test_cat, verbose=0)\n",
    "\n",
    "results = {}\n",
    "results['ResNet_Style'] = {\n",
    "    'test_acc': resnet_test_acc,\n",
    "    'best_val_acc': max(history_resnet.history['val_accuracy'])\n",
    "}\n",
    "\n",
    "print(f\"ResNet-style Test Accuracy: {resnet_test_acc*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_jdOcfHorOsO",
   "metadata": {
    "id": "_jdOcfHorOsO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NnDts7-ryurB",
   "metadata": {
    "id": "NnDts7-ryurB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
